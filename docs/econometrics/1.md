# 计量经济学重点

## 概述

### 计量经济学的概述

#### 计量经济学的定义

把经济理论、数学和统计推断作为工具，应用于经济现象分析的社会科学。

#### 计量经济学的内容体系

- 广义计量经济学和狭义计量经济学
- 初、中、高级计量经济学
- 理论计量经济学和应用计量经济学
- 经典计量经济学和非经典计量经济学
- 微观计量经济学和宏观计量经济学

### 建立经典计量经济学模型的步骤

#### 理论模型的建立

- 确定模型包含的变量

  - 正确理解和把握所研究的经济现象中暗含的经济学理论和经济行为规律。

  - 选择变量考虑数据的可得性。

  - 选择变量时要考虑所有入选变量间的关系，使得每一个变量都是独立的。

- 确定模型的数学形式
- 拟定理论模型中待估参数的理论期望值

#### 样本数据的收集

- 分类：时间序列数据、截面数据和面板数据
- 质量：完整性、准确性、可比性和一致性

#### 模型参数的估计

#### 模型的检验

- 经济意义的检验
- 统计检验
- 计量经济学检验
- 模型预测检验

#### 经济学成功的三要素

- 理论、方法和数据

---

## 一元线性回归模型

### 回归分析概述

#### 回归分析的基本概念

变量之间的相互关系：函数关系和相关关系。

相关分析和回归分析：相关性程度的大小可以通过 **相关系数** 来测量。总体的相关系数为：

$${\rho_{XY}=\frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)} } }$$

如果给出一组样本，则样本的相关系数为：

$$
{r_{XY}=\frac{\sum (X_i-\overline{X} ) (Y_i-\overline{Y})}{\sqrt{\sum (X_i-\overline{X})^2 \sum (Y_i-\overline{Y} )^2} }  }
$$

> 相关分析和回归分析既有联系又有区别。两者都是研究非确定性变量间的依赖关系。相关分析从统计数据测度变量间的相关程度，而无需考察两者是否存在因果关系。因此相关分析中的变量地位是对称的。回归分析中的变量地位是不对称的，回归分析更加注重变量间的依赖关系。

#### 总体回归函数

在给定解释变量 X 的条件下，被解释变量 Y 的期望轨迹称为总体回归曲线。相应的函数称为**总体回归函数。**

$$
E(Y|X)=f(X)=\beta_0+\beta_1X
$$

#### 随机误差项

将总体样本和条件均值之差记为离差，称为**随机干扰项**。

$$
\mu=Y-E(Y|E)=\beta_0+\beta_1X+\mu
$$

随机误差项代表以下六个方面的原因：

1. 代表未知的影响因素
2. 代表残缺数据
3. 代表众多细小影响因素
4. 代表数据观测误差
5. 代表模型设定误差
6. 变量的内在随机性

#### **_样本回归函数_**

实际情况往往是通过抽样得到总体样本，再通过样本信息再估计总体函数。由于样本取自总体，我们近似将该直线代表总体直线，称为样本回归线，其函数称为**样本回归函数**。

$$
\hat{Y}=f(x)=\hat{\beta_0 }+\hat{\beta_1X}
$$

若将样本回归函数看作总体回归函数的近似替代，则得到**样本回归模型**。

$$
Y=\hat Y+\hat \mu=\hat \beta_0+\hat \beta_1X+e
$$

> 在这里 $\hat Y$ 为 $E(Y|X)$ 的估计量；$\hat \beta_i$ 为 $\beta_i$ 的估计量。e 称为样本残差项。

### 一元线性回归模型的参数估计

#### 最小二乘法

通过解正规方程组可以得到一元线性回归模型的参数估计值。

$$
\left\{\begin{matrix}
  \sum (Y_i-\hat \beta_0-\hat{\beta_1X_i} )=0 \\
  \sum X_i(Y_i-\hat \beta_0-\hat{\beta_1X_i})=0
\end{matrix}\right.
$$

$$
{\large \left\{\begin{matrix}{}
\hat \beta_0 =\frac{\sum X^2_i\sum Y_i-\sum X_i\sum X_iY_i}{n\sum X^2_i-(\sum X_i)^2}\\
\hat \beta _1=\frac{n\sum Y_iX_i-\sum Y_i\sum X_i}{n\sum X^2_i-(\sum X_i)^2}
\end{matrix}\right.
}
$$

我们记：

$$
\sum x_i^2=\sum (X_i-\overline{X} )^2=\sum X_i^2-\frac{1}{n}\sum (X_i)^2 \\
\sum x_iy_i=\sum (X_i-\overline{X} )(Y_i-\overline{Y} )=\sum X_iY_i-\frac{1}{n}\sum X_i\sum Y_i
$$

于是我们得到 OLS 估计量的离差形式：

$$
{\large \left\{\begin{matrix}
\hat \beta_1=\frac{\sum x_iy_i}{\sum x_i^2}  \\
\hat \beta_0=\overline{Y}-\hat \beta_1\overline{X}
\end{matrix}\right. }
$$

#### 拟合优度

记总离差平方和 TSS、回归平方和 ESS 和残差平方和 RSS 分别为：

$$
TSS:\sum y_i^2=\sum (Y_i-\overline Y)^2 \\
ESS:\sum \hat y^2_i=\sum (\hat Y_i-\overline Y)^2\\
RSS:\sum e^2_i=\sum (Y_i-\hat Y_i)^2
$$

模型的拟合优度可以根据下列式子计算：

$$
R^2=\frac{ESS}{TSS}=1-\frac{RSS}{TSS} \ \ \ R^2 \in \left [ 0,1 \right ]
$$

拟合优度和 1 越接近，就说明回归线和样本点拟合得越好。在实际计算拟合优度时，有一个较为简单的公式：

$$
R^2=\hat \beta_1^2 \left(\frac{\sum x_i^2}{\sum y_i^2}\right)
$$

### 基本假设和统计性质

#### 一元线性回归模型的基本假设

1. 回归模型是正确的。
2. 解释变量 X 在简单随机抽样中有变异性。
3. 给定解释变量 X 的任何值，随机干扰项的均值为零。
4. 随机干扰项具有给定 X 任何值条件下的同方差性和不序列相关性。
5. 随机干扰项服从零均值、同方差的正态分布。

#### 普通最小二乘估计量的统计性质

1. 线性性。估计量是 Y 的线性组合。
2. 无偏性。估计量的期望等于总体回归参数。
3. 有效性。普通最小二乘估计量有最小方差。

> 普通最小二乘估计量具有的线性性、无偏性、有效性等优良性质，称为**最佳线性无偏量**。

### 一元线性回归模型的统计检验

#### 参数估计量概率分布和随机干扰项的方差估计

在 μ 是正态分布的假设下，以 X 为条件，Y 呈正态分布。因此 $\hat \beta$ 也服从正态分布。因此有：

$$
\hat \beta_1 \sim  N \left(\beta_1,\frac{\sigma^2}{\sum x_i^2}\right) \\
\hat \beta_2 \sim N \left(\beta_0, \frac{\sum X_i^2}{n\sum x_i^2}\sigma^2\right)
$$

在估计参数的方差表达式中，都存在随机干扰项的方差 σ^2^ 。我们从残差出发，对总体方差进行估计。

$$
\hat \sigma^2=\frac{\sum e_i^2}{n-2}
$$

在随机干扰项方差被估计出后，参数的方差的样本估计量分别是：

$$
S^2_\hat {\beta_1}=\hat \sigma^2/\sum x_i^2, \ \ \ S^2_\hat{\beta_0}=\hat \sigma^2\sum X_i^2/n\sum x_i^2
$$

#### 变量的显著性检验

如果真实的 σ^2^ 未知，而用它的无偏估计量替代时，可以得到如下统计量，该统计量被称为 **t 统计量**。

$$
t=\frac{\hat \beta_1-\beta_1}{\sqrt{\hat \sigma^2/\sum x_i^2}}=\frac{\hat \beta_1-\beta_1}{S_\hat{\beta_1}}\\
t=\frac{\hat \beta_0-\beta_0}{\sqrt{\hat \sigma^2\sum X_i^2/n\sum x_i^2}}=\frac{\hat \beta_0-\beta_0}{S_\hat{\beta_0}}\\
$$

上述统计量都服从自由度为 n-2 的 t 分布。可以用 t 统计量来检验显著性。

#### 参数检验的置信区间估计

参数的置信区间估计的基本做法是，预选一个概率为 α，并求一个正数 δ，使得随机区间包含 β 的真值概率为 1-α。1-α 称为置信度，该区间称为置信区间，α 称为显著性水平。在 1-α 置信度下的 β 置信区间是：

$$
\left ( \hat{\beta _j}-t_\frac{\alpha}{2}\times S_\hat{\beta _j}, \ \ \hat{\beta _j}+t_\frac{\alpha}{2}\times S_\hat{\beta _j}      \right )
$$

**如何缩小置信区间？**

1. 增大样本容量 n 可使样本参数估计量的标准差减小；同时在同样的显著性水平下，n 越大，t 分布表中的临界值越小。
2. 提高模型的拟合优度。

---

## 经典单方程计量经济学模型

### 多元线性回归模型

#### 多元线性模型的形式

多元线性回归模型（总体回归函数的随机表达形式，也是**总体回归模型**）的一般形式为：

$$
Y=\beta_0+\beta_1X_1+\beta_2X_2+\cdots+\beta_kX_k+\mu
$$

​ 其中 k 为解释变量数目，β 称为回归参数，模型中解释变量的数目为 k+1。

总体回归函数的非随机表达形式，也就是**总体回归函数**的表示为：

$$
E(Y|X_1,X_2,\cdots X_k)=\beta_0+\beta_1X_1+\beta_2X_2\cdots+\beta_kX_k
$$

**样本回归模型**的一般形式为：

$$
Y=\hat \beta_0+\hat \beta_1X_1+\hat \beta_2X_2+\cdots+\hat \beta_kX_k+e
$$

​ 其中 e 称为残差或者剩余项，可以看成总体回归函数中的随机干扰项 μ 的近似值。

**样本回归函数**的一般形式为：

$$
\hat Y=\hat \beta_0+\hat \beta_1X_1+\hat \beta_2X_2+\cdots+\hat \beta_kX_k
$$

#### 回归模型的基本假定

**_假设一_**：回归模型是正确设立的。

**_假设二_**：解释变量在简单随机抽取的样本中具有变异性。

**_假设三_**：随机干扰项具有条件零均值性。

**_假设四_**：随机干扰项具有条件同方差及不序列相关性。

**_假设五_**：随机干扰项满足正态分布。

### 多元线性回归模型的参数估计

使用最小二乘估计（OLS）来对参数进行估计，由于涉及矩阵，不要求掌握。需要掌握的是随机干扰项 μ 的方差的最小二乘估计量：

$$
\hat \sigma^2=\frac{\sum e^2_i}{n-k-1}=\frac{e^,e}{n-k-1}
$$

#### 拟合优度

对于多元回归模型来说，我们记 TSS 为总离差平方和，ESS 为回归平方和，RSS 为残差平方和（剩余平方和）。则有

$$
\sum y^2_i=\sum \hat y^2_i-\sum e_i^2+2\sum \hat y_ie_i \ \ \Rightarrow \ \ TSS=ESS+RSS
$$

> 回归平方和反应了总离差平方和中可由样本解释的部分，值越大，残差平方和越小，标明样本回归取向与样本观测值的拟合程度越高。

$$
R^2=\frac{ESS}{TSS}=1-\frac{RSS}{TSS}
$$

#### 调整的拟合优度

在模型中增加一个解释变量，拟合优度的值往往增大。但是，实际情况是，由增加解释变量个数引起的拟合优度的增大与拟合好坏无关，因此多元回归模型中比较拟合优度就不适合了。

在样本容量一定的情况下，**增加解释变量必定使得自由度减少**，所以我们引入调整的拟合优度：

$$
\overline R^2=1-\frac{RSS/(n-k-1)}{TSS/(n-1)}
$$

​ 其中 n-k-1 为残差平方和的自由度，n-1 为总离差平方和的自由度。在多元线性回归模型中，**调整的拟合优度往往用来帮助判断是否将一个变量作为解释变量引入模型**。

### 多元线性回归模型的统计性质和统计检验

#### 统计性质

- **_小样本性质_**
  - 线性性，参数估计量是被解释变量观测值的线性组合。
  - 无偏性，各解释变量样本值给定的情况下，参数估计量的期望等于总体回归参数。
  - 有效性，所有线性无偏的估计量中，普通最小二乘估计量具有最小方差。
- **_大样本性质_**
  - 一致性
  - 渐进有效性

#### 变量的显著性检验

参数估计量的概率分布，矩阵运算，应该不考。

变量的显著性检验（t 检验），在多元线性回归模型中，无论是大样本还是小样本，都满足以下正态分布：

$$
t=\frac{\hat \beta_j-\beta_j}{S_\hat{\beta_j}}=\frac{\hat \beta_j-\beta_j}{\sqrt {c_{jj}\hat \sigma^2}} \sim t(n-k-1)
$$

​ 其中，$S_\hat \beta$ 为标准差，随机干扰项的方差计算可以用上面的式子。在回归分析中，我们设计两个假设：

$$
H_0:\beta_j=0\\
H_1:\beta_j\ne 0
$$

给定显著性水平 $\alpha$，得到临界值 $t_{\frac{\alpha}{2}}(n-k-1)$，可以根据下列式子来决定拒绝或接受原假设：

$$
\left |t  \right | >t_{\frac{\alpha}{2}}(n-k-1) \\
\left | t \right | \le t_{\frac{\alpha}{2}}(n-k-1)
$$

> 如果满足第一个式子，那么就拒绝 $H_0$，则变量显著性不为零。如果满足第二个式子，那么就不拒绝 $H_0$，则变量显著为零。

#### 参数的置信区间

在 $1-\alpha$ 的置信度下，$\beta_j$ 的置信区间是：

$$
\left ( \hat \beta_j-t_\frac{\alpha}{2} \times S_{\hat{\beta_j}}, \hat \beta_j+t_\frac{\alpha}{2} \times S_{\hat{\beta_j}} \right )
$$

如何增大置信区间：

- 增大样本容量 n。
- 提高模型的拟合优度，减少残差平方和。
- 提高样本观测值的分散度。

#### 方程的显著性检验

方程的显著性检验主要是检验模型中各 X 的参数**是否显著不为零**，我们选择以下假设：

$$
H_0:\beta_0=0,\beta_2=0\cdots,\beta_k=0 \\
H_1:\beta_j(j=1,2,\cdots,k)\ 不全为零
$$

在原假设处理的条件下，统计量

$$
F=\frac{ESS/k}{RSS/(n-k-1)}
$$

服从自由度为 `(k,n-k-1)` 的 F 分布。给定显著性水平 $\alpha$ 可通过是否有

$$
F>F_\alpha(k,n-k-1)
$$

来拒绝或者不拒绝原假设 $H_0$，来判断原方程总体上的线性关系是否显著成立。

> **在一元线性回归中，t 检验和 F 检验是一致的。**

拟合优度和方程显著性检验之间存在下面关系：

$$
F=\frac{R^2/k}{(1-R^2)/(n-k-1)}
$$

> 由上式可知，F 与 R^2^ 同向变化。

#### 样本容量问题

最小样本容量：$n\ge k+1$ 样本容量必须不少于模型中解释变量的数目（包括常数项）。

基本要求：一般检验认为，当 $n\ge 30$ 或者至少 $n\ge 3(k+1)$ 时，才能满足模型的基本需求。

### 多元线性回归的预测

矩阵计算，必不可能考

### 可化为线性的多元非线性模型

#### 模型的类型与转换

倒数模型、多项式模型与变量的直接置换：

$$
\frac{1}{Q}=a+b\frac{1}{P}+\mu \ \ \Rightarrow \ \ Y=a+bX+\mu
$$

幂函数模型、指数函数模型与函数变化法：

$$
Q=AK^\alpha L^\beta e^\mu \ \ \Rightarrow \ \  \ln Q=\ln A+\alpha\ln K+\beta\ln L+\mu
$$

复杂函数模型与级数展开：不可能考

### 含有虚拟变量的多元线性回归模型

#### 虚拟变量的模型

根据某一些因素的属性，构造只取 0 和 1 的人工变量，称为**虚拟变量**，记为 $D$ 。例如文化程度的虚拟变量为：

$$
\mathcal{D=\left\{\begin{matrix}
 1 \ 本科及以上学历 \\
 0 \ \ \  本科以下学历
\end{matrix}\right.}
$$

#### 虚拟变量的引入

一个以性别为虚拟变量来考察员工薪资的模型如下：

$$
Y_i=\beta_0+\beta_1X_1+\beta_2D_i+\mu_i
$$

​ 其中，$Y_i$ 为员工薪资；$X_i$ 为工龄；若是男性，$D_i=1$，若是女性，$D_i=0$。

**_加法方式_**：在模型中将虚拟变量以加法方式引入模型。在该模型中，仍然假定 $E(\mu_i|X,D)=0$，则有

$$
E(Y_i|X,D=0)=\beta_0+\beta_1X_i
\\
E(Y_i|X,D=1)=(\beta_0+\beta_2)+\beta_1X_i
$$

> 加法方式的特点：加法方式引入的虚拟变量，具有同斜率不同截距的特点，也就是说通过引入虚拟变量改变的是起始点，而不改变速率。

**_乘法方式_**：在模型中将虚拟变量以乘法方式引入模型。则有：

$$
Y_i=\beta_0+\beta_1 X_i+\beta_2D_iX_i+\mu_i
$$

在假定 $E(\mu_i|X,D)=0$ 下，则有其函数可化为：

$$
E(Y_i|X,D=0)=\beta_0+\beta_1X_i
\\
E(Y_i|X,D=1)=\beta_0+(\beta_1+\beta_2)X_i
$$

> 乘法方式的特点：乘法方式引入的虚拟变量，具有同截距不同斜率的特点，也就是说通过引入虚拟变量改变的是速率，而不是起始点。

#### 虚拟变量设置的原则

每一定性变量所需的虚拟变量个数要比该定性变量的类别数少 1，即如果有 m 个定性变量，只在模型中引入 m-1 个虚拟变量就可以了。

### 受约束的线性回归

#### 模型参数的线性回归

对一个线性回归模型：

$$
Y=\beta_0+\beta_1X_1+\beta_2X_2+\cdots+\beta_kX_k+\mu
$$

施加约束：$\beta_1+\beta_2=1$ ，$\beta_{k-1}=\beta_k$

则施加上述约束条件后，可以得到：

$$
Y=\beta_0+\beta_1X_1+(1-\beta_1)X_2+\cdots+\beta_{k-1}X_{k-1}+\beta_{k-1}X_k+\mu
$$

> 通常来说，对模型施加约束条件会降低模型的解释能力。

在小样本下，可以使用 F 统计量来对其进行检验：

$$
F=\frac{(RSS_R-RSS_U)/(k_U-k_R)}{RSS_U/n-k_U-1} \sim F(k_U-k_R,n-k_U-1)
$$

#### 对回归模型的增加或者减少解释变量

对于下面两个回归模型：

$$
Y=\beta_0+\beta_1X_1+\cdots+\beta_kX_k+\mu \\
Y=\beta_0+\beta_1X_1+\cdots+\beta_kX_k+\cdots+\beta_{k+q}X_{k+q}+\mu
$$

第一个式子可以看作第二个式子施加约束条件的受约束回归：

$$
H_o:\beta_{k+1}=\beta_{k+2}=\cdots=\beta_{k+q}=0
$$

相应的 F 统计量是：

$$
F=\frac{(RSS_R-RSS_U)/q}{RSS_U/[n-(k+q+1)]}\sim F[q,n-(k+q+1)]
$$

> 若约束条件为真，则额外的变量对 Y 没有解释能力，则 F 统计量较小。若约束条件为假，意味着额外的变量对 Y 有较强的解释能力，则 F 统计量较大。

####　检验不同组之间回归函数的差异

对同一模型，取两个不同样本：

$$
Y=\beta_0+\beta_1X_1+\cdots+\beta_kX_k+\mu_1 \\
Y=\alpha_0+\alpha_1X_1+\cdots+\alpha_kX_k+\mu_2
$$

如果 $\beta=\alpha$ 则表示，两个组别在回归函数上没有差别，因此可以作为原假设：

$$
H_0:\beta=\alpha
$$

因此，可以用 F 统计量进行检验：

$$
F=\frac{[RSS_R-(RSS_1+RSS_2)]/(k+1)}{RSS_1+RSS_2/[n_1+n_2-2(k+1)]}\sim F[k+1,n_1+n_2-2(k+1)]
$$

> 检验两个样本组在样本回归函数上有无差异的步骤为：首先对两个样本公式进行最小二乘回归，得到残差平方和；然后将两个样本合并成一个大样本进行回归，得到大样本下的残差平方和，通过 F 统计量在预先给定的显著性水平下进行假设检验。**如果 F 大于临界值，则拒绝原假设，说米两个样本组的回归函数有差异**。

---

##　放宽基本假定的模型

### 多重共线性

#### 多重共线性的含义

如果两个或多个解释变量之间出现了相关性，则称为存在多重共线性。对于下列方程：

$$
c_1X_{i1}+c_2X_{i2}+c_3X_{i3}+\cdots+c_kX_{ik}=0
$$

如果其中的 c 不全为 0，即某一个变量可以用其他解释变量的线性组合来表示，则称解释变量间存在**完全共线性**。如果存在：

$$
c_1X_{i1}+c_2X_{i2}+c_3X_{i3}+\cdots+c_kX_{ik}+\nu_i=0


$$

其中 c 不全为 0，v 为随机误差项，则称为**近似共线性**。

#### 实际问题中的多重共线性

- 经济变量相关的共同趋势
- 模型设定不谨慎
- 样本资料的限制

#### 多重共线性的后果

- 完全线性下参数估计量不存在
- 近似共线性下普通最小二乘估计量的方差变大。
- 参数估计量经济意义不合理
- 变量的显著性检验和模型的预测功能失去意义

#### 多重共线性的检验

多重共线性检验的任务是：检验多重共线性是否存在；估计多重共线性的范围。

- 对两个解释变量的模型，采用**简单相关系数法**。求 $X_1$ 和 $X_2$ 的简单相关系数 $r$，若 $|r|$ 接近与 1，则说明两遍量存在较强的多重共线性。
- 对多个解释变量的模型，采用**综合统计检验法**。在普通最小二乘法下，模型的 $R^2$ 和 F 值较大，但各参数估计值的 t 检验值较小，说明各解释变量对 Y 的联合线性作用显著。

如果存在多重共线性，需要确定是由哪些变量引起的。

- **_判定系数法_**：使模型中每个解释变量分别以其余解释变量为解释变量进行回归运算，并计算拟合优度。若在某一种形式中判定系数较大，则说明被解释变量 $X_j$ 与其他解释变量存在共线性。
- **_逐步回归法_**：以 Y 为被解释变量，逐个引入解释变量，构成回归模型，进行模型估计。如果拟合优度变化显著，则说明新引入的变量是一个独立解释变量；如果拟合优度变化不是很显著，则说明新引入的变量不是一个独立变量，具有共线性。

#### 克服多重共线性

找出引起多重共线性的变量，将它排除出去，是最为有效的克服多重共线性的方法。需要注意，排除某些解释变量后，会对模型的估计量产生变化。

### 异方差性

#### 异方差的类型

在异方差的情况下，$\sigma^2$ 不是常数，它随 $X_i$ 的变化而变化，即 $\sigma^2=f(X_i)$。异方差有三种类型：

1. 单调递增型
2. 单调递减型
3. 复杂型

#### 实际经济问题中的异方差

#### 异方差性的后果

- 参数估计量非有效
- 变量的显著性检验失去意义
- 模型预测失效

#### 异方差性检验

图示法：可以用 $Y-X$ 的散点图进行判断。看是否存在明显的散点扩大、缩小或复杂趋势。

**_B-P 检验_**：对任意线性模型，同方差性可以表示为下面方程为线性函数

$$
\mu_i^2=\delta_0+\delta_1X_{i1}+\delta_2X_{i2}+\cdots+\delta_kX_{ik}+\varepsilon_i
$$

​ 那么检验同方差性就是检验以下假设：

$$
H_0:\delta_1=\delta_2=\cdots=\delta_k=0
$$

通过 F 统计量来检验该假设：

$$
F=\frac{R^2_{e^2}/k}{(1-R^2_{e^2})/(n-k-1)}
$$

---

**_White 检验_**：

假设回归模型为：

$$
Y_i=\beta_0+\beta_1X_{i1}+\beta_2X_{i2}+\mu_i
$$

可先对该模型做最小二乘回归，然后得到残差项的平方，然后做辅助回归：

$$
e^2_i=\delta_0+\delta_1X_{i1}+\delta_2X_{i2}+\delta_3X_{i1}^2+\delta_4X_{i2}^2+\delta_5X_{i1}X_{i2}+\varepsilon_i
$$

要检验的同 f 方差性假设为：$H_0:\delta_0=\delta_1= \cdots =\delta_5 $ 。依然可以使用 B-P 检验的 F 统计量来检验是否拒绝假设。

#### 异方差的修正

**_加权最小二乘法_** 是对原模型加权，使之变为一个新的不存在异方差性的模型，然后采用普通最小二乘法估计其参数。加权的思想是，在采用普通最小二乘法时，对较小的残差平方赋予较大的权数，对较大的残差平方赋予较小的权数，以提高参数的估计精度。

**加权最小二乘法，就是对加了权重的残差平方和实施普通最小二乘法**：

$$
\sum w_ie_i^2=\sum w_i[Y_i-(\hat \beta_0+\hat \beta_1X_{i1}+\cdots+\hat \beta_kX_{ik})]^2
$$

​ 其中 $w_i$ 是权数。

实施加权最小二乘法的关键就是寻找适当的权，如果发现：

$$
Var(\mu_i|X_{i1},X_{i2},\cdots,X_{ik})=\sigma^2f(X_{i1},X_{i2},\cdots,X_{ik})
$$

​ 则加权最小二乘法的权即为：

$$
\frac{1}{\sqrt{f(X_{i1},X_{i2},\cdots,X_{ik})}}
$$

---

## 时间序列的经济学模型

### 试剂序列模型的序列相关性

#### 序列相关性

对于模型

$$
Y_i=\beta_0+\beta_1X_{i1}+\beta_2X_{i2}+\cdots+\beta_kX_{ik}+\mu_i\ ,\  t=1,2,\cdots ,n
$$

在其他假设仍然成立的条件下，随机干扰项序列相关意味着：$Cov(\mu_1,\mu_2)=E(\mu_1,\mu_2)\ne0$，称为**一阶序列相关**，或**自相关**。自相关可以写成以下形式：

$$
\mu_i=\rho \ \mu_{i-1}+\varepsilon_i \ \ \ \ -1<\rho<1
$$

​ 其中 $\rho$ 称为**_自协方差系数_**，或一阶自相关系数。

#### 实际经济问题中的序列相关性

- 经济变量固有的惯性
- 模型设定的偏误
- 数据的编造

#### 序列相关性的后果

- 参数估计量非有效
- 变量的显著性失去意义
- 模型预测失效

#### 序列相关性的检验

图示法

回归检验法

**_D.W. 检验法_**：该方法假定的条件是

- 解释变量严格外生
- 随机误差项为一阶自回归形式
- 回归模型中不应含有滞后被解释变量作为解释变量
- 回归模型含有截距项

对原假设 $H_0:\rho=0$，即 $\mu_i$ 不存在一阶自回归，构造如下统计量：

$$
D.W.=\frac{\sum(e_i-e_{i-1})^2}{\sum e_i^2}
$$

- 如果存在完全一阶正相关，则 $\rho \approx 1, \ \ D.W. \approx 0$
- 如果存在完全一阶负相关，则 $\rho \approx -1, \ \ D.W. \approx 4$
- 如果完全不相关，则 $\rho = 0, \ \ D.W.=2 $

**_拉格朗日乘数法_**：不要求解释变量的严格外生性。也被称为 **_GB 检验_**。
